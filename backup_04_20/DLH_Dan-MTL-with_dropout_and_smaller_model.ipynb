{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "\n",
    "FILE_NAME_SUFFIX = \".multi_admission\" #\"_1000\"\n",
    "DATASET_PATH = \"Datasets/\"\n",
    "\n",
    "def read_samples(input_file, file_name_suffix):\n",
    "    file_name = DATASET_PATH + input_file + file_name_suffix\n",
    "    return pd.read_csv(file_name, error_bad_lines=False, keep_default_na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "patients = read_samples(\"PATIENTS.csv\", FILE_NAME_SUFFIX)\n",
    "patients['birth_date'] = patients[\"DOB\"].apply(lambda s: (datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S') - datetime.datetime(1970,1,1)).days)\n",
    "\n",
    "admissions = read_samples(\"ADMISSIONS.csv\", FILE_NAME_SUFFIX)\n",
    "admissions[\"admit_date\"] = admissions[\"ADMITTIME\"].apply(lambda s: (datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S') - datetime.datetime(1970,1,1)).days)\n",
    "admissions[\"discharge_date\"] = admissions[\"DISCHTIME\"].apply(lambda s: (datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S') - datetime.datetime(1970,1,1)).days)\n",
    "admissions['LOS'] = admissions[\"discharge_date\"] - admissions[\"admit_date\"]\n",
    "\n",
    "diagnoses = read_samples(\"DIAGNOSES_ICD.csv\", FILE_NAME_SUFFIX)\n",
    "procedures = read_samples(\"PROCEDURES_ICD.csv\", FILE_NAME_SUFFIX)\n",
    "icu_stays = read_samples(\"ICUSTAYS.csv\", FILE_NAME_SUFFIX)\n",
    "notes = read_samples(\"NOTEEVENTS.csv\", FILE_NAME_SUFFIX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limit the patients to the ones with more than 1 admission:\n",
      " count    7537.000000\n",
      "mean        2.652647\n",
      "std         1.621112\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max        42.000000\n",
      "Name: num_admissions, dtype: float64\n",
      "Prevalence of patients with more than 1 admission:  1.0\n",
      "Prevalence of patients with more than 2 admissions:  0.31537747114236436\n",
      "Prevalence of patients with more than 3 admissions:  0.13732254212551412\n",
      "Prevalence of patients with more than 4 admissions:  0.06992171951704923\n",
      "Prevalence of patients with more than 5 admissions:  0.03728273849011543\n"
     ]
    }
   ],
   "source": [
    "patients = patients.set_index(\"SUBJECT_ID\", drop=False)\n",
    "patients[\"num_admissions\"] = admissions.groupby(\"SUBJECT_ID\").size().to_frame(\"num_admissions\")\n",
    "patients = patients[patients.num_admissions > 1]\n",
    "print(\"Limit the patients to the ones with more than 1 admission:\\n\", patients.num_admissions.describe())\n",
    "print(\"Prevalence of patients with more than 1 admission: \", len(patients[patients[\"num_admissions\"] > 1]) / len(patients))\n",
    "print(\"Prevalence of patients with more than 2 admissions: \", len(patients[patients[\"num_admissions\"] > 2]) / len(patients))\n",
    "print(\"Prevalence of patients with more than 3 admissions: \", len(patients[patients[\"num_admissions\"] > 3]) / len(patients))\n",
    "print(\"Prevalence of patients with more than 4 admissions: \", len(patients[patients[\"num_admissions\"] > 4]) / len(patients))\n",
    "print(\"Prevalence of patients with more than 5 admissions: \", len(patients[patients[\"num_admissions\"] > 5]) / len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = admissions[admissions.SUBJECT_ID.isin(patients.SUBJECT_ID)]\n",
    "procedures = procedures[procedures.SUBJECT_ID.isin(patients.SUBJECT_ID)]\n",
    "diagnoses = diagnoses[diagnoses.SUBJECT_ID.isin(patients.SUBJECT_ID)]\n",
    "icu_stays = icu_stays[icu_stays.SUBJECT_ID.isin(patients.SUBJECT_ID)]\n",
    "notes = notes[notes.SUBJECT_ID.isin(patients.SUBJECT_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record length before the final admission\n",
      " count    7533.000000\n",
      "mean      242.149608\n",
      "std       579.288149\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%        13.000000\n",
      "75%        84.000000\n",
      "max      4145.000000\n",
      "Name: record_length, dtype: float64\n",
      "Interval before the final admission\n",
      " count    7533.000000\n",
      "mean      445.034382\n",
      "std       678.907514\n",
      "min       -19.000000\n",
      "25%        25.000000\n",
      "50%       131.000000\n",
      "75%       570.000000\n",
      "max      4108.000000\n",
      "Name: final_admission_interval, dtype: float64\n",
      "Prevalence of readmission in 30 days =  0.27517579938967757\n"
     ]
    }
   ],
   "source": [
    "last_admission = admissions[admissions.groupby(['SUBJECT_ID'])['admit_date'].transform(max) == admissions['admit_date']]\n",
    "previous_admissions = admissions[admissions.groupby(['SUBJECT_ID'])['admit_date'].transform(max) != admissions['admit_date']]\n",
    "patients[\"record_start_date\"] = previous_admissions.groupby(\"SUBJECT_ID\").admit_date.agg(['min'])\n",
    "patients[\"record_end_date\"] = previous_admissions.groupby(\"SUBJECT_ID\").discharge_date.agg(['max'])\n",
    "patients[\"record_length\"] = patients.record_end_date - patients.record_start_date\n",
    "patients[\"final_admission_date\"] = admissions.groupby(\"SUBJECT_ID\").admit_date.agg(['max'])\n",
    "patients[\"final_admission_interval\"] = patients.final_admission_date - patients.record_end_date\n",
    "\n",
    "print(\"Record length before the final admission\\n\", patients.record_length.describe())\n",
    "\n",
    "print(\"Interval before the final admission\\n\", patients.final_admission_interval.describe())\n",
    "\n",
    "print(\"Prevalence of readmission in 30 days = \", len(patients[patients.final_admission_interval < 30]) / len(patients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of ICU admission in 30 days =  0.006103224094467295\n"
     ]
    }
   ],
   "source": [
    "icu_stays[\"admit_date\"] = icu_stays[\"INTIME\"].apply(lambda s: (datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S') - datetime.datetime(1970,1,1)).days)\n",
    "final_icu_admission = icu_stays[icu_stays.groupby(['SUBJECT_ID'])['admit_date'].transform(max) != icu_stays['admit_date']]\n",
    "patients[\"final_icu_admission_date\"] = final_icu_admission.groupby(\"SUBJECT_ID\").admit_date.agg(['min'])\n",
    "patients[\"final_icu_admission_interval\"] = patients.final_icu_admission_date - patients.record_end_date\n",
    "print(\"Prevalence of ICU admission in 30 days = \", len(patients[(patients[\"final_icu_admission_interval\"] >= 0) & (patients[\"final_icu_admission_interval\"] < 30)]) / len(patients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       procedure_freq_by_icd9_code\n",
      "count                  1513.000000\n",
      "mean                     54.035030\n",
      "std                     275.114179\n",
      "min                       1.000000\n",
      "25%                       1.000000\n",
      "50%                       4.000000\n",
      "75%                      19.000000\n",
      "max                    6505.000000\n",
      "       procedure_freq_by_patient\n",
      "count                7364.000000\n",
      "mean                   11.101983\n",
      "std                     8.891169\n",
      "min                     1.000000\n",
      "25%                     5.000000\n",
      "50%                     9.000000\n",
      "75%                    15.000000\n",
      "max                    98.000000\n",
      "       procedure_freq_by_admission\n",
      "count                 17393.000000\n",
      "mean                      4.700454\n",
      "std                       3.961372\n",
      "min                       1.000000\n",
      "25%                       2.000000\n",
      "50%                       3.000000\n",
      "75%                       6.000000\n",
      "max                      40.000000\n",
      "           freq\n",
      "ICD9_CODE      \n",
      "3893       6505\n",
      "9604       3440\n",
      "966        3203\n",
      "9904       2940\n",
      "9671       2796\n",
      "9672       2225\n",
      "3995       2030\n",
      "3891       1620\n",
      "8856       1497\n",
      "9915       1364\n",
      "3961       1364\n",
      "4513       1339\n",
      "3324       1316\n",
      "8872       1218\n",
      "5491       1078\n",
      "3895        982\n",
      "3722        920\n",
      "9907        828\n",
      "3491        824\n",
      "3723        792\n"
     ]
    }
   ],
   "source": [
    "print(procedures.groupby(\"ICD9_CODE\").size().to_frame(\"procedure_freq_by_icd9_code\").describe())\n",
    "print(procedures.groupby(\"SUBJECT_ID\").size().to_frame(\"procedure_freq_by_patient\").describe())\n",
    "print(procedures.groupby(\"HADM_ID\").size().to_frame(\"procedure_freq_by_admission\").describe())\n",
    "\n",
    "print(procedures.groupby(\"ICD9_CODE\").size().to_frame(\"freq\").sort_values(\"freq\", ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       diagnosis_freq_by_icd9_code\n",
      "count                  4894.000000\n",
      "mean                     53.192889\n",
      "std                     258.042880\n",
      "min                       1.000000\n",
      "25%                       1.000000\n",
      "50%                       4.000000\n",
      "75%                      20.000000\n",
      "max                    7183.000000\n",
      "       diagnosis_freq_by_patient\n",
      "count                7537.000000\n",
      "mean                   34.539737\n",
      "std                    28.731059\n",
      "min                     2.000000\n",
      "25%                    18.000000\n",
      "50%                    28.000000\n",
      "75%                    41.000000\n",
      "max                   540.000000\n",
      "       diagnosis_freq_by_admission\n",
      "count                 19993.000000\n",
      "mean                     13.020857\n",
      "std                       6.860812\n",
      "min                       1.000000\n",
      "25%                       9.000000\n",
      "50%                      11.000000\n",
      "75%                      17.000000\n",
      "max                      39.000000\n",
      "           freq\n",
      "ICD9_CODE      \n",
      "4019       7183\n",
      "4280       6588\n",
      "42731      5285\n",
      "5849       4318\n",
      "41401      4183\n",
      "25000      3738\n",
      "2724       3259\n",
      "51881      3081\n",
      "5990       2961\n",
      "53081      2623\n",
      "2449       2230\n",
      "486        2199\n",
      "2859       2186\n",
      "496        2051\n",
      "2720       2042\n",
      "2762       1915\n",
      "V4581      1820\n",
      "V5861      1819\n",
      "99592      1796\n",
      "2851       1756\n"
     ]
    }
   ],
   "source": [
    "print(diagnoses.groupby(\"ICD9_CODE\").size().to_frame(\"diagnosis_freq_by_icd9_code\").describe())\n",
    "print(diagnoses.groupby(\"SUBJECT_ID\").size().to_frame(\"diagnosis_freq_by_patient\").describe())\n",
    "print(diagnoses.groupby(\"HADM_ID\").size().to_frame(\"diagnosis_freq_by_admission\").describe())\n",
    "\n",
    "print(diagnoses.groupby(\"ICD9_CODE\").size().to_frame(\"freq\").sort_values(\"freq\", ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    739127.000000\n",
      "mean        280.506953\n",
      "std         381.865602\n",
      "min           0.000000\n",
      "25%          72.000000\n",
      "50%         160.000000\n",
      "75%         318.000000\n",
      "max        7980.000000\n",
      "Name: text_len, dtype: float64\n",
      "       notes_freq_by_patient\n",
      "count            7535.000000\n",
      "mean               98.092502\n",
      "std               117.930373\n",
      "min                 1.000000\n",
      "25%                34.000000\n",
      "50%                62.000000\n",
      "75%               116.000000\n",
      "max              1420.000000\n",
      "       notes_freq_by_admission\n",
      "count             19758.000000\n",
      "mean                 37.408999\n",
      "std                 948.520727\n",
      "min                   1.000000\n",
      "25%                   8.000000\n",
      "50%                  15.000000\n",
      "75%                  31.000000\n",
      "max              133139.000000\n"
     ]
    }
   ],
   "source": [
    "notes['text_len'] = notes['TEXT'].apply(lambda s: len(s.split()))\n",
    "print(notes[\"text_len\"].describe())\n",
    "print(notes.groupby(\"SUBJECT_ID\").size().to_frame(\"notes_freq_by_patient\").describe())\n",
    "print(notes.groupby(\"HADM_ID\").size().to_frame(\"notes_freq_by_admission\").describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    21740.000000\n",
      "mean      1603.497148\n",
      "std        884.371393\n",
      "min          9.000000\n",
      "25%       1008.000000\n",
      "50%       1527.000000\n",
      "75%       2111.000000\n",
      "max       7980.000000\n",
      "Name: text_len, dtype: float64\n",
      "       notes_freq_by_patient\n",
      "count            7451.000000\n",
      "mean                2.917729\n",
      "std                 1.935627\n",
      "min                 1.000000\n",
      "25%                 2.000000\n",
      "50%                 2.000000\n",
      "75%                 3.000000\n",
      "max                47.000000\n",
      "       notes_freq_by_admission\n",
      "count             19050.000000\n",
      "mean                  1.141207\n",
      "std                   0.438223\n",
      "min                   1.000000\n",
      "25%                   1.000000\n",
      "50%                   1.000000\n",
      "75%                   1.000000\n",
      "max                   7.000000\n"
     ]
    }
   ],
   "source": [
    "discharge_summaries = notes[notes.CATEGORY == \"Discharge summary\"]\n",
    "print(discharge_summaries[\"text_len\"].describe())\n",
    "print(discharge_summaries.groupby(\"SUBJECT_ID\").size().to_frame(\"notes_freq_by_patient\").describe())\n",
    "print(discharge_summaries.groupby(\"HADM_ID\").size().to_frame(\"notes_freq_by_admission\").describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3902.000000\n",
      "mean      663.113275\n",
      "std       811.485606\n",
      "min         0.000000\n",
      "25%        80.250000\n",
      "50%       316.500000\n",
      "75%       937.750000\n",
      "max      4328.000000\n",
      "Name: death_interval, dtype: float64\n",
      "Prevalence of death in 30 days =  0.05532705320419265\n",
      "Prevalence of death =  0.5177126177524214\n"
     ]
    }
   ],
   "source": [
    "patients[\"death_date\"] = patients[\"DOD\"].apply(lambda s: (datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S') - datetime.datetime(1970,1,1)).days if s != '' else np.nan)\n",
    "patients['death_interval'] = patients.death_date - patients.record_end_date\n",
    "print(patients['death_interval'].describe())\n",
    "print(\"Prevalence of death in 30 days = \", len(patients[patients.death_interval < 30]) / len(patients))\n",
    "print(\"Prevalence of death = \", len(patients[patients.death_interval >= 0]) / len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       procedure_freq_by_icd9_code\n",
      "count                  1024.000000\n",
      "mean                     79.286133\n",
      "std                     331.499928\n",
      "min                       2.000000\n",
      "25%                       4.000000\n",
      "50%                      10.500000\n",
      "75%                      38.000000\n",
      "max                    6505.000000\n",
      "       procedure_freq_by_patient\n",
      "count                7361.000000\n",
      "mean                   11.029616\n",
      "std                     8.854558\n",
      "min                     1.000000\n",
      "25%                     5.000000\n",
      "50%                     9.000000\n",
      "75%                    15.000000\n",
      "max                    98.000000\n",
      "       procedure_freq_by_admission\n",
      "count                 17355.000000\n",
      "mean                      4.678133\n",
      "std                       3.937743\n",
      "min                       1.000000\n",
      "25%                       2.000000\n",
      "50%                       3.000000\n",
      "75%                       6.000000\n",
      "max                      39.000000\n"
     ]
    }
   ],
   "source": [
    "# Limit the procedures to the most common procedures\n",
    "NUM_PROCEDURE_CODES = 1024\n",
    "top_procedures = procedures.groupby(\"ICD9_CODE\").size().to_frame(\"freq\").sort_values(\"freq\", ascending=False).head(NUM_PROCEDURE_CODES).index.tolist()\n",
    "procedures = procedures[procedures.ICD9_CODE.isin(top_procedures)]\n",
    "print(procedures.groupby(\"ICD9_CODE\").size().to_frame(\"procedure_freq_by_icd9_code\").describe())\n",
    "print(procedures.groupby(\"SUBJECT_ID\").size().to_frame(\"procedure_freq_by_patient\").describe())\n",
    "print(procedures.groupby(\"HADM_ID\").size().to_frame(\"procedure_freq_by_admission\").describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       diagnosis_freq_by_icd9_code\n",
      "count                  4096.000000\n",
      "mean                     63.361328\n",
      "std                     280.940588\n",
      "min                       1.000000\n",
      "25%                       2.000000\n",
      "50%                       7.000000\n",
      "75%                      28.000000\n",
      "max                    7183.000000\n",
      "       diagnosis_freq_by_patient\n",
      "count                7537.000000\n",
      "mean                   34.433860\n",
      "std                    28.696845\n",
      "min                     2.000000\n",
      "25%                    18.000000\n",
      "50%                    27.000000\n",
      "75%                    41.000000\n",
      "max                   539.000000\n",
      "       diagnosis_freq_by_admission\n",
      "count                 19990.000000\n",
      "mean                     12.982891\n",
      "std                       6.851016\n",
      "min                       1.000000\n",
      "25%                       9.000000\n",
      "50%                      11.000000\n",
      "75%                      17.000000\n",
      "max                      39.000000\n"
     ]
    }
   ],
   "source": [
    "# Limit the diagnoses to the most common diagnoses\n",
    "NUM_DIAGNOSIS_CODES = 4096\n",
    "top_diagnoses = diagnoses.groupby(\"ICD9_CODE\").size().to_frame(\"freq\").sort_values(\"freq\", ascending=False).head(NUM_DIAGNOSIS_CODES).index.tolist()\n",
    "diagnoses = diagnoses[diagnoses.ICD9_CODE.isin(top_diagnoses)]\n",
    "print(diagnoses.groupby(\"ICD9_CODE\").size().to_frame(\"diagnosis_freq_by_icd9_code\").describe())\n",
    "print(diagnoses.groupby(\"SUBJECT_ID\").size().to_frame(\"diagnosis_freq_by_patient\").describe())\n",
    "print(diagnoses.groupby(\"HADM_ID\").size().to_frame(\"diagnosis_freq_by_admission\").describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7537\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "other_admission_info_dim = 2 # age and LOS\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, patients, admissions, procedures, top_procedures, diagnoses, top_diagnoses, prediction_window):\n",
    "        top_procedures_dict = dict(zip(top_procedures, range(len(top_procedures))))\n",
    "        top_diagnoses_dict = dict(zip(top_diagnoses, range(len(top_procedures), len(top_procedures) + len(top_diagnoses))))\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        for _, patient in patients.iterrows():\n",
    "            patient_admissions = []\n",
    "            for _, admission in admissions[admissions.SUBJECT_ID == patient.SUBJECT_ID].iterrows():\n",
    "                icd9_codes = []\n",
    "                for _, admission_procedure in procedures[procedures.HADM_ID == admission.HADM_ID].iterrows():\n",
    "                    icd9_codes.append(top_procedures_dict[admission_procedure.ICD9_CODE])\n",
    "                for _, admission_diagnosis in diagnoses[diagnoses.HADM_ID == admission.HADM_ID].iterrows():\n",
    "                    icd9_codes.append(top_diagnoses_dict[admission_diagnosis.ICD9_CODE])\n",
    "                other_info = [(admission.admit_date - patient.birth_date) / 36500.0, admission.LOS / 100.0]\n",
    "                patient_admissions.append((other_info, icd9_codes))\n",
    "            self.x.append(patient_admissions)\n",
    "            self.y.append([patient.final_admission_interval < prediction_window, patient.death_interval < prediction_window])\n",
    "            # self.y.append(patient.final_admission_interval < prediction_window)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "\n",
    "dataset = CustomDataset(patients, previous_admissions, procedures, top_procedures, diagnoses, top_diagnoses, 30)\n",
    "print(len(dataset))\n",
    "# for i in range(len(dataset)):\n",
    "#     x, y = dataset[i]\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    TODO: Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "        sequences to the sample shape (max # visits, encoding size). The padding infomation\n",
    "        is stored in `mask`.\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, encoding size) of type torch.long\n",
    "        masks: a tensor of shape (# patiens, max # visits, encoding size) of type torch.bool\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    max_admissions = 0\n",
    "    max_icd9_codes = 0\n",
    "    for sequence in sequences:\n",
    "        max_admissions = max(max_admissions, len(sequence))\n",
    "        for admission in sequence:\n",
    "            (other_info, icd9_codes) = admission\n",
    "            max_icd9_codes = max(max_icd9_codes, len(icd9_codes))\n",
    "    \n",
    "    dim = (num_patients, max_admissions, max_icd9_codes)\n",
    "    x_data = np.zeros(dim)\n",
    "    x_other_data = np.zeros((num_patients, max_admissions, other_admission_info_dim))\n",
    "    masks_data = np.full(dim, False)\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        num_admissions = len(sequence)\n",
    "        for j, admission in enumerate(sequence):\n",
    "            (other_info, icd9_codes) = admission\n",
    "            for k, icd9_code in enumerate(icd9_codes):\n",
    "                x_data[i][j][k] = icd9_code\n",
    "                masks_data[i][j][k] = True\n",
    "            for k, other_admission_info in enumerate(other_info):\n",
    "                x_other_data[i][j][k] = other_admission_info\n",
    "       \n",
    "    x = torch.tensor(x_data, dtype=torch.long)\n",
    "    x_other = torch.tensor(x_other_data, dtype=torch.float)\n",
    "    masks = torch.tensor(masks_data, dtype=torch.bool)\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    return x, x_other, masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 39]) torch.Size([10, 5, 2]) torch.Size([10, 5, 39]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, x_other, masks, y = next(loader_iter)\n",
    "print(x.shape, x_other.shape, masks.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 5652\n",
      "Length of val dataset: 1885\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset)*0.75)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)\n",
    "combined_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_embeddings_with_mask(x, masks):\n",
    "    (batch_size, visits, diags, embedding_dim) = x.shape\n",
    "    masks = masks.unsqueeze(3).expand(batch_size, visits, diags, embedding_dim)\n",
    "    output = torch.sum(x * masks, dim=2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, masks):\n",
    "    batch_size, visits, embedding_dim = hidden_states.shape\n",
    "    masks = torch.sum(masks, 2)\n",
    "    masks = torch.min(masks, torch.ones_like(masks))\n",
    "    masks = torch.sum(masks, 1)\n",
    "    masks = masks - torch.ones_like(masks)\n",
    "    masks = masks.unsqueeze(1).expand(batch_size, embedding_dim).unsqueeze(1)\n",
    "    masks = torch.max(masks, torch.zeros_like(masks)) # FIXME: data cleaning problem! some patients have no admission\n",
    "    last_visit = torch.gather(hidden_states, 1, masks)\n",
    "    last_visit = torch.flatten(last_visit, 1, 2)\n",
    "    return last_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveRNN(\n",
       "  (embedding): Embedding(5120, 16)\n",
       "  (rnn): GRU(18, 16, batch_first=True)\n",
       "  (linear1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear2): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (activation2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NaiveRNN(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, other_admission_info_dim, hidden_state_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings, embedding_size)\n",
    "        self.rnn = torch.nn.GRU(embedding_size + other_admission_info_dim, hidden_state_size, batch_first=True)\n",
    "        self.linear1 = torch.nn.Linear(hidden_state_size, hidden_state_size)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.linear2 = torch.nn.Linear(hidden_state_size, output_size)\n",
    "        self.activation2 = torch.nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def forward(self, x, x_other, masks):\n",
    "        (batch_size, num_admissions, _) = x.shape\n",
    "        hidden_state = torch.zeros(1, batch_size, self.hidden_state_size)\n",
    "        hidden_states = []\n",
    "        embeddings = self.embedding(x)\n",
    "        sum_embeddings = sum_embeddings_with_mask(embeddings, masks)\n",
    "        combined_admission_info = torch.cat((sum_embeddings, x_other), 2)\n",
    "        output, _ = self.rnn(combined_admission_info)\n",
    "        output = get_last_visit(output, masks)\n",
    "        output = self.activation1(self.linear1(output))\n",
    "        output = self.dropout(output)\n",
    "        output = self.activation2(self.linear2(output))\n",
    "        return output.squeeze()\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "naive_rnn = NaiveRNN(num_embeddings=len(top_procedures)+len(top_diagnoses), embedding_size = 16, other_admission_info_dim=other_admission_info_dim, hidden_state_size=16, output_size=2)\n",
    "naive_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(naive_rnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    Y1_pred = []\n",
    "    Y1_true = []\n",
    "    Y2_pred = []\n",
    "    Y2_true = []\n",
    "    for x, x_other, masks, y in val_loader:\n",
    "        with torch.no_grad():\n",
    "            pred = model(x, x_other, masks)\n",
    "            # Y1_true.extend(y.detach().numpy().tolist())\n",
    "            # Y1_pred.extend(pred.detach().numpy().reshape(-1).tolist())\n",
    "            Y1_true.extend(y.detach().numpy()[:,0].tolist())\n",
    "            Y1_pred.extend(pred.detach().numpy()[:,0].reshape(-1).tolist())\n",
    "            Y2_true.extend(y.detach().numpy()[:,1].tolist())\n",
    "            Y2_pred.extend(pred.detach().numpy()[:,1].reshape(-1).tolist())\n",
    "    \n",
    "    # print(len(Y1_true), len(Y1_pred), len(Y2_true), len(Y2_pred))\n",
    "    precision1, recall1, f11, _ = precision_recall_fscore_support(Y1_true, np.array(Y1_pred)>0.5, average='binary')\n",
    "    roc_auc1 = roc_auc_score(Y1_true, Y1_pred)\n",
    "    precision2, recall2, f12, _ = precision_recall_fscore_support(Y2_true, np.array(Y2_pred)>0.5, average='binary')\n",
    "    roc_auc2 = roc_auc_score(Y2_true, Y2_pred)\n",
    "    \n",
    "\n",
    "    \n",
    "    return precision1, recall1, f11, roc_auc1, precision2, recall2, f12, roc_auc2, len(Y1_pred), sum(Y1_true), sum(Y2_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1: N=1885 Prevalence=0.279 P=0.363 R=0.352 F1=0.357 ROC AUC=0.582\n",
      "Task2: N=1885 Prevalence=0.051 P=0.074 R=0.042 F1=0.053 ROC AUC=0.589\n"
     ]
    }
   ],
   "source": [
    "# precision1, recall1, f11, roc_auc1 = eval_model(naive_rnn, val_loader)\n",
    "# print('Task1: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f}'.format(precision1, recall1, f11, roc_auc1))\n",
    "\n",
    "precision1, recall1, f11, roc_auc1, precision2, recall2, f12, roc_auc2, n, p1, p2 = eval_model(naive_rnn, val_loader)\n",
    "print('Task1: N={} Prevalence={:.3f} P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f}'.format(n, p1/n, precision1, recall1, f11, roc_auc1))\n",
    "print('Task2: N={} Prevalence={:.3f} P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f}'.format(n, p2/n, precision2, recall2, f12, roc_auc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training loss = 109.88243162631989  validation loss = 27.95983412861824\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.000 R=0.000 F1=0.000 ROC AUC=0.529 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.451 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.000 R=0.000 F1=0.000 ROC AUC=0.524 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.481 Prevalence=0.057\n",
      "Epoch 1: training loss = 74.50674030184746  validation loss = 23.974238634109497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Set N=1885\n",
      "\tTask1: P=0.000 R=0.000 F1=0.000 ROC AUC=0.544 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.458 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.000 R=0.000 F1=0.000 ROC AUC=0.560 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.529 Prevalence=0.057\n",
      "Epoch 2: training loss = 71.54288829863071  validation loss = 23.646841377019882\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.000 R=0.000 F1=0.000 ROC AUC=0.557 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.479 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=1.000 R=0.001 F1=0.001 ROC AUC=0.593 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.586 Prevalence=0.057\n",
      "Epoch 3: training loss = 69.8240269869566  validation loss = 23.376047432422638\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=1.000 R=0.023 F1=0.045 ROC AUC=0.564 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.500 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.932 R=0.026 F1=0.052 ROC AUC=0.619 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.653 Prevalence=0.057\n",
      "Epoch 4: training loss = 68.18777894973755  validation loss = 23.214558765292168\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.837 R=0.078 F1=0.143 ROC AUC=0.569 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.524 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.894 R=0.104 F1=0.186 ROC AUC=0.653 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.712 Prevalence=0.057\n",
      "Epoch 5: training loss = 66.22455130517483  validation loss = 23.103648468852043\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.722 R=0.108 F1=0.188 ROC AUC=0.577 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.554 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.831 R=0.143 F1=0.245 ROC AUC=0.689 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.770 Prevalence=0.057\n",
      "Epoch 6: training loss = 64.05389349162579  validation loss = 23.191801354289055\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.597 R=0.135 F1=0.220 ROC AUC=0.581 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.562 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.794 R=0.189 F1=0.306 ROC AUC=0.724 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.812 Prevalence=0.057\n",
      "Epoch 7: training loss = 61.59763365983963  validation loss = 23.33986420929432\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.571 R=0.152 F1=0.240 ROC AUC=0.590 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.580 Prevalence=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Set N=5652\n",
      "\tTask1: P=0.823 R=0.228 F1=0.357 ROC AUC=0.763 Prevalence=0.274 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.847 Prevalence=0.057\n",
      "Epoch 8: training loss = 58.53101445734501  validation loss = 23.841863438487053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Set N=1885\n",
      "\tTask1: P=0.500 R=0.202 F1=0.287 ROC AUC=0.590 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.590 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.799 R=0.331 F1=0.468 ROC AUC=0.795 Prevalence=0.274 \n",
      "\tTask2: P=0.500 R=0.003 F1=0.006 ROC AUC=0.874 Prevalence=0.057\n",
      "Epoch 9: training loss = 55.1456031948328  validation loss = 24.454258769750595\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.490 R=0.192 F1=0.276 ROC AUC=0.588 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.586 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.859 R=0.343 F1=0.490 ROC AUC=0.831 Prevalence=0.274 \n",
      "\tTask2: P=0.750 R=0.028 F1=0.054 ROC AUC=0.897 Prevalence=0.057\n",
      "Epoch 10: training loss = 51.48483915627003  validation loss = 25.143074110150337\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.461 R=0.224 F1=0.302 ROC AUC=0.590 Prevalence=0.279 \n",
      "\tTask2: P=0.000 R=0.000 F1=0.000 ROC AUC=0.586 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.866 R=0.447 F1=0.590 ROC AUC=0.861 Prevalence=0.274 \n",
      "\tTask2: P=0.867 R=0.081 F1=0.148 ROC AUC=0.917 Prevalence=0.057\n",
      "Epoch 11: training loss = 47.58250288665295  validation loss = 26.31312507390976\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.441 R=0.236 F1=0.307 ROC AUC=0.589 Prevalence=0.279 \n",
      "\tTask2: P=0.077 R=0.010 F1=0.018 ROC AUC=0.596 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.891 R=0.510 F1=0.648 ROC AUC=0.885 Prevalence=0.274 \n",
      "\tTask2: P=0.938 R=0.187 F1=0.312 ROC AUC=0.930 Prevalence=0.057\n",
      "Epoch 12: training loss = 43.53240688890219  validation loss = 27.42139659821987\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.421 R=0.264 F1=0.325 ROC AUC=0.587 Prevalence=0.279 \n",
      "\tTask2: P=0.091 R=0.010 F1=0.019 ROC AUC=0.587 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.892 R=0.579 F1=0.702 ROC AUC=0.908 Prevalence=0.274 \n",
      "\tTask2: P=0.944 R=0.262 F1=0.410 ROC AUC=0.944 Prevalence=0.057\n",
      "Epoch 13: training loss = 39.68394376337528  validation loss = 28.775770992040634\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.388 R=0.285 F1=0.329 ROC AUC=0.588 Prevalence=0.279 \n",
      "\tTask2: P=0.100 R=0.021 F1=0.034 ROC AUC=0.594 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.885 R=0.664 F1=0.759 ROC AUC=0.925 Prevalence=0.274 \n",
      "\tTask2: P=0.952 R=0.371 F1=0.534 ROC AUC=0.956 Prevalence=0.057\n",
      "Epoch 14: training loss = 35.978578843176365  validation loss = 30.38848254084587\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.380 R=0.287 F1=0.327 ROC AUC=0.587 Prevalence=0.279 \n",
      "\tTask2: P=0.100 R=0.031 F1=0.048 ROC AUC=0.598 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.911 R=0.706 F1=0.795 ROC AUC=0.939 Prevalence=0.274 \n",
      "\tTask2: P=0.957 R=0.480 F1=0.639 ROC AUC=0.963 Prevalence=0.057\n",
      "Epoch 15: training loss = 32.47827135026455  validation loss = 32.113986015319824\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.379 R=0.295 F1=0.332 ROC AUC=0.585 Prevalence=0.279 \n",
      "\tTask2: P=0.097 R=0.031 F1=0.047 ROC AUC=0.589 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.934 R=0.742 F1=0.827 ROC AUC=0.952 Prevalence=0.274 \n",
      "\tTask2: P=0.984 R=0.570 F1=0.722 ROC AUC=0.971 Prevalence=0.057\n",
      "Epoch 16: training loss = 29.11427740007639  validation loss = 33.721378192305565\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.362 R=0.323 F1=0.341 ROC AUC=0.586 Prevalence=0.279 \n",
      "\tTask2: P=0.098 R=0.042 F1=0.058 ROC AUC=0.594 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.925 R=0.808 F1=0.862 ROC AUC=0.962 Prevalence=0.274 \n",
      "\tTask2: P=0.975 R=0.617 F1=0.756 ROC AUC=0.977 Prevalence=0.057\n",
      "Epoch 17: training loss = 25.929321222007275  validation loss = 36.06767724454403\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.371 R=0.319 F1=0.343 ROC AUC=0.585 Prevalence=0.279 \n",
      "\tTask2: P=0.070 R=0.031 F1=0.043 ROC AUC=0.599 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.945 R=0.818 F1=0.877 ROC AUC=0.969 Prevalence=0.274 \n",
      "\tTask2: P=0.978 R=0.701 F1=0.817 ROC AUC=0.981 Prevalence=0.057\n",
      "Epoch 18: training loss = 23.169905245304108  validation loss = 38.382408663630486\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.365 R=0.331 F1=0.347 ROC AUC=0.585 Prevalence=0.279 \n",
      "\tTask2: P=0.080 R=0.042 F1=0.055 ROC AUC=0.591 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.955 R=0.849 F1=0.899 ROC AUC=0.974 Prevalence=0.274 \n",
      "\tTask2: P=0.979 R=0.726 F1=0.834 ROC AUC=0.984 Prevalence=0.057\n",
      "Epoch 19: training loss = 20.710951941087842  validation loss = 40.34650456905365\n",
      "  Validation Set N=1885\n",
      "\tTask1: P=0.363 R=0.352 F1=0.357 ROC AUC=0.582 Prevalence=0.279 \n",
      "\tTask2: P=0.074 R=0.042 F1=0.053 ROC AUC=0.589 Prevalence=0.051\n",
      "  Training Set N=5652\n",
      "\tTask1: P=0.950 R=0.880 F1=0.914 ROC AUC=0.980 Prevalence=0.274 \n",
      "\tTask2: P=0.984 R=0.779 F1=0.870 ROC AUC=0.987 Prevalence=0.057\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, combined_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        for x, x_other, masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model.forward(x, x_other, masks)\n",
    "            loss = criterion(torch.flatten(y_pred), torch.flatten(y))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "        val_loss = 0\n",
    "        for x, x_other, masks, y in val_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model.forward(x, x_other, masks)\n",
    "            loss = criterion(torch.flatten(y_pred), torch.flatten(y))\n",
    "            loss.backward()\n",
    "            val_loss+=loss.item()\n",
    "        print('Epoch {}: training loss = {}  validation loss = {}'.format(epoch, train_loss, val_loss))\n",
    "        precision1, recall1, f11, roc_auc1, precision2, recall2, f12, roc_auc2, n, p1, p2 = eval_model(model, val_loader)\n",
    "        print('  Validation Set N={}\\n\\tTask1: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f} Prevalence={:.3f} \\n\\tTask2: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f} Prevalence={:.3f}'.format(n, precision1, recall1, f11, roc_auc1, p1/n, precision2, recall2, f12, roc_auc2, p2/n))\n",
    "        precision1, recall1, f11, roc_auc1, precision2, recall2, f12, roc_auc2, n, p1, p2 = eval_model(model, train_loader)\n",
    "        print('  Training Set N={}\\n\\tTask1: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f} Prevalence={:.3f} \\n\\tTask2: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f} Prevalence={:.3f}'.format(n, precision1, recall1, f11, roc_auc1, p1/n, precision2, recall2, f12, roc_auc2, p2/n))\n",
    "        # precision1, recall1, f11, roc_auc1, precision2, recall2, f12, roc_auc2, n, p1, p2 = eval_model(model, combined_loader)\n",
    "        # print('  Combined Set N={}\\n\\tTask1: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f} Prevalence={:.3f} \\n\\tTask2: P={:.3f} R={:.3f} F1={:.3f} ROC AUC={:.3f} Prevalence={:.3f}'.format(n, precision1, recall1, f11, roc_auc1, p1/n, precision2, recall2, f12, roc_auc2, p2/n))\n",
    "        \n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "train(naive_rnn, train_loader, val_loader, combined_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
